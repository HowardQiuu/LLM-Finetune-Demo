# Qwen3-1.7B LoRA å¾®è°ƒ Demo

æœ¬é¡¹ç›®å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ [PEFT (LoRA)](https://huggingface.co/docs/peft/index)  
å¯¹ [Qwen3-1.7B](https://huggingface.co/Qwen/Qwen3-1.7B) æ¨¡å‹è¿›è¡Œ **ä½èµ„æºå¾®è°ƒ**ã€‚

é€šè¿‡ç»“åˆ **4-bit é‡åŒ– (bitsandbytes)** ä¸ **LoRA å‚æ•°é«˜æ•ˆå¾®è°ƒ**ï¼Œ  
æˆ‘ä»¬å¯ä»¥åœ¨ä»… 15GB å·¦å³æ˜¾å­˜çš„ç¯å¢ƒä¸‹è¿è¡Œ Qwen3-1.7B çš„å¾®è°ƒã€‚

---

## âœ¨ åŠŸèƒ½äº®ç‚¹
- âœ… ä½¿ç”¨ [BitsAndBytes](https://github.com/TimDettmers/bitsandbytes) è¿›è¡Œ **4bit é‡åŒ–**ï¼Œå‡å°‘æ˜¾å­˜å ç”¨  
- âœ… ä½¿ç”¨ [LoRA](https://arxiv.org/abs/2106.09685) è¿›è¡Œ **é«˜æ•ˆå¾®è°ƒ**  
- âœ… åœ¨ Colab å…è´¹ GPU ä¸Šå¯è¿è¡Œ  
- âœ… æä¾›å®Œæ•´è®­ç»ƒ + æ¨ç†ä»£ç ç¤ºä¾‹  

---

## ğŸ“¦ å®‰è£…ä¾èµ–

```bash
pip install -U bitsandbytes transformers accelerate peft datasets
```

ğŸš€ è®­ç»ƒ

è¿è¡Œä»¥ä¸‹è„šæœ¬ä¼šï¼š

- åŠ è½½ Qwen3-1.7Bï¼ˆ4bit é‡åŒ–ï¼‰

- ä½¿ç”¨ LoRA æ’å…¥å¯è®­ç»ƒå‚æ•°

- åœ¨ IMDB æ•°æ®é›†ä¸Šè¿›è¡Œ æƒ…æ„Ÿåˆ†ç±»æ–‡æœ¬å»ºæ¨¡ å¾®è°ƒ
```bash
python Qwen3-1.7B-Finetune-demo.py
```

ä¸»è¦è®­ç»ƒå‚æ•°ï¼š
- batch_size=1ï¼ˆé¿å… OOMï¼‰

- gradient_accumulation_steps=4ï¼ˆç­‰æ•ˆ batch=4ï¼‰

- learning_rate=2e-4

- num_train_epochs=1

è®­ç»ƒå®Œæˆåï¼ŒLoRA é€‚é…å™¨ä¼šä¿å­˜åœ¨ ./qwen3_lora_demo/ã€‚

ğŸ’¬ æ¨ç†æµ‹è¯•

è®­ç»ƒå®Œæˆåå¯ä»¥è¿›è¡Œæ¨ç†

```python
query = "I really enjoyed this movie because"
inputs = tokenizer(query, return_tensors="pt").to(model.device)

with torch.no_grad():
    outputs = model.generate(**inputs, max_length=150)

print(tokenizer.decode(outputs[0], skip_special_tokens=True))

```
ç¤ºä¾‹è¾“å‡ºï¼ˆå› éšæœºæ€§è€Œä¸åŒï¼‰ï¼š
```kotlin
ğŸ¤– Model response:
I really enjoyed this movie because the acting was great and the story was touching...
```
